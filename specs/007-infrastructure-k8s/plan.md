# Implementation Plan: Local Kubernetes Deployment (Phase IV)

**Branch**: `007-infrastructure-k8s` | **Date**: 2026-02-04 | **Spec**: [spec.md](./spec.md)
**Input**: Feature specification from `/specs/007-infrastructure-k8s/spec.md`

## Summary

Deploy the Phase III Todo Chatbot (Next.js frontend + FastAPI backend + MCP server) to a local Minikube Kubernetes cluster using Helm charts. This plan leverages AI-assisted DevOps tools (Docker AI Gordon, kubectl-ai, kagent) to automate infrastructure tasks while maintaining beginner-friendly, zero-cost local deployment.

## Technical Context

**Language/Version**: Multi-language (Python 3.12 backend, Node.js 20 frontend)
**Primary Dependencies**: Docker Desktop, Minikube, Helm 3, kubectl
**AI Tools**: Docker AI (Gordon), kubectl-ai, kagent
**Storage**: External PostgreSQL (Neon) - no local database needed
**Testing**: Manual verification via kubectl, helm test, curl
**Target Platform**: Local Minikube cluster (Docker driver)
**Project Type**: Web application (frontend + backend)
**Performance Goals**: Pods ready within 2 minutes, deployment under 5 minutes
**Constraints**: 4GB RAM minimum, local-only (no cloud), zero cost tools
**Scale/Scope**: 2 frontend replicas, 1 backend replica, single namespace

## Constitution Check

*GATE: Infrastructure deployment - constitution principles apply to tooling choices*

| Principle | Status | Notes |
|-----------|--------|-------|
| Library-First | N/A | Infrastructure, not library code |
| CLI Interface | PASS | All tools are CLI-based (helm, kubectl, docker) |
| Test-First | ADAPTED | Verification steps replace unit tests for infra |
| Simplicity | PASS | Minimal viable K8s setup, no over-engineering |

## Project Structure

### Documentation (this feature)

```text
specs/007-infrastructure-k8s/
├── plan.md              # This file
├── research.md          # AI tools research
├── quickstart.md        # Developer deployment guide
└── tasks.md             # Implementation tasks (generated by /sp.tasks)
```

### Source Code (repository root)

```text
# Existing application structure (no changes)
backend/
├── src/
├── Dockerfile           # UPDATE: Optimize for K8s
└── requirements.txt

frontend/
├── src/
├── Dockerfile           # NEW: Multi-stage build
└── package.json

# NEW: Kubernetes infrastructure
k8s/
└── todo-app/            # Helm chart
    ├── Chart.yaml
    ├── values.yaml
    ├── .helmignore
    └── templates/
        ├── _helpers.tpl
        ├── configmap.yaml
        ├── secrets.yaml
        ├── backend-deployment.yaml
        ├── backend-service.yaml
        ├── frontend-deployment.yaml
        └── frontend-service.yaml

# NEW: Helper scripts
scripts/
├── local-deploy.sh      # One-command deployment
└── local-teardown.sh    # Clean uninstall
```

**Structure Decision**: Web application pattern with separate Helm chart directory at repository root for infrastructure code.

---

## Phase IV Execution Plan

### Phase 0: Prerequisites & Environment Setup

#### Step 0.1: Verify Prerequisites
**Tool**: Standard CLI

```text
Actions:
1. Check Docker Desktop is installed and running
2. Check Minikube is installed (v1.32+)
3. Check Helm is installed (v3.14+)
4. Check kubectl is installed
5. Verify 4GB+ RAM available for Minikube
```

**Verification**:
```bash
docker --version
minikube version
helm version
kubectl version --client
```

#### Step 0.2: Install AI-Assisted Tools (Optional but Recommended)
**Tool**: Standard CLI + pip/npm

```text
AI Tools to Install:
1. Docker AI (Gordon) - Built into Docker Desktop (enable in settings)
2. kubectl-ai - Install via: pip install kubectl-ai
3. kagent - Install via: pip install kagent

Fallback: If AI tools unavailable, use standard CLI commands
```

---

### Phase 1: Dockerization Strategy

#### Step 1.1: Analyze Existing Dockerfiles
**Tool**: Docker AI (Gordon)

```text
Command: docker ai "analyze the backend/Dockerfile and suggest optimizations for Kubernetes deployment"

Expected Output:
- Recommendations for multi-stage builds
- Security improvements (non-root user)
- Health check additions
- Image size reduction strategies
```

#### Step 1.2: Generate Frontend Dockerfile
**Tool**: Docker AI (Gordon)

```text
Command: docker ai "generate a production Dockerfile for a Next.js 16 application with:
- Multi-stage build (deps, builder, runner)
- Standalone output mode
- Non-root user
- Health check endpoint
- Port 3000 exposed"

Output: frontend/Dockerfile (new file)
Target Size: <500MB
```

#### Step 1.3: Optimize Backend Dockerfile
**Tool**: Docker AI (Gordon)

```text
Command: docker ai "optimize the backend/Dockerfile for Kubernetes with:
- Python 3.12-slim base
- Non-root user
- Health check for /health endpoint
- Port 8000 exposed
- Minimal layer count"

Output: backend/Dockerfile (updated)
Target Size: <300MB
```

#### Step 1.4: Create .dockerignore Files
**Tool**: Docker AI (Gordon)

```text
Command: docker ai "generate .dockerignore for a monorepo with Next.js frontend and FastAPI backend"

Output:
- .dockerignore (root)
- frontend/.dockerignore
- backend/.dockerignore (verify existing)
```

#### Step 1.5: Build and Test Images Locally
**Tool**: Standard Docker CLI

```text
Actions:
1. Build frontend image: docker build -t todo-frontend:local ./frontend
2. Build backend image: docker build -t todo-backend:local ./backend
3. Verify image sizes: docker images | grep todo-
4. Test frontend: docker run --rm -p 3000:3000 todo-frontend:local
5. Test backend: docker run --rm -p 8000:8000 --env-file .env todo-backend:local
```

**Verification**: Both containers start without errors, respond on their ports

---

### Phase 2: Minikube Cluster Setup

#### Step 2.1: Start Minikube Cluster
**Tool**: Standard Minikube CLI

```text
Command: minikube start --driver=docker --memory=4096 --cpus=2 --disk-size=20g

Configuration:
- Driver: Docker (most compatible)
- Memory: 4GB (minimum for 3 pods)
- CPUs: 2 (adequate for local dev)
- Disk: 20GB (room for images)
```

#### Step 2.2: Verify Cluster Status
**Tool**: kagent (AI-assisted)

```text
Command: kagent analyze cluster

Expected Analysis:
- Node status and resources
- Available capacity
- Recommended workload limits
- Potential issues

Fallback: kubectl cluster-info && kubectl get nodes -o wide
```

#### Step 2.3: Configure Docker Environment for Minikube
**Tool**: Standard CLI

```text
Command: eval $(minikube docker-env)

Purpose: Build images directly into Minikube's Docker daemon
Benefit: No need to push to registry, images immediately available
```

#### Step 2.4: Build Images in Minikube Context
**Tool**: Standard Docker CLI (in Minikube context)

```text
Commands:
1. eval $(minikube docker-env)
2. docker build -t todo-frontend:local ./frontend
3. docker build -t todo-backend:local ./backend
4. docker images | grep todo-

Verification: Images visible in Minikube's Docker daemon
```

---

### Phase 3: Helm Chart Structure

#### Step 3.1: Initialize Helm Chart
**Tool**: Helm CLI

```text
Command: helm create k8s/todo-app

Generated Structure:
k8s/todo-app/
├── Chart.yaml           # Chart metadata
├── values.yaml          # Default configuration
├── .helmignore          # Files to ignore
├── charts/              # Dependencies (empty)
└── templates/           # K8s manifests
    ├── _helpers.tpl     # Template helpers
    ├── deployment.yaml  # Remove default
    ├── service.yaml     # Remove default
    └── ...              # Remove other defaults
```

#### Step 3.2: Design values.yaml Structure
**Tool**: kubectl-ai (for best practices)

```text
Command: kubectl-ai "suggest values.yaml structure for a helm chart deploying:
- Frontend: Next.js, 2 replicas, NodePort 30080
- Backend: FastAPI, 1 replica, ClusterIP 8000
- ConfigMap: FRONTEND_URL, BACKEND_URL, ENVIRONMENT
- Secrets: DATABASE_URL, JWT_SECRET_KEY, OPENAI_API_KEY"

values.yaml Sections:
1. global: namespace, labels
2. frontend: image, replicas, service, resources, env
3. backend: image, replicas, service, resources, env
4. configmap: non-sensitive values
5. secrets: sensitive values (base64 encoded)
```

#### Step 3.3: Define Template Files
**Tool**: kubectl-ai

```text
Templates to Create:
1. _helpers.tpl - Common labels, selectors, names
2. configmap.yaml - Non-sensitive configuration
3. secrets.yaml - Sensitive configuration
4. backend-deployment.yaml - Backend pods with probes
5. backend-service.yaml - ClusterIP service
6. frontend-deployment.yaml - Frontend pods with probes
7. frontend-service.yaml - NodePort service

For each template, use:
Command: kubectl-ai "generate [template-name] for [component] with [requirements]"
```

#### Step 3.4: Configure Health Probes
**Tool**: kubectl-ai

```text
Command: kubectl-ai "generate liveness and readiness probes for:
- Backend: GET /health on port 8000, initial delay 10s
- Frontend: GET / on port 3000, initial delay 15s"

Probe Configuration:
- livenessProbe: Restart container if unhealthy
- readinessProbe: Remove from service if not ready
- initialDelaySeconds: Allow container startup time
- periodSeconds: Check frequency
- failureThreshold: Failures before action
```

---

### Phase 4: Deployment with kubectl-ai

#### Step 4.1: Create Namespace
**Tool**: kubectl-ai

```text
Command: kubectl-ai "create namespace todo-app with labels app=todo-chatbot"

Equivalent: kubectl create namespace todo-app --dry-run=client -o yaml | kubectl apply -f -
```

#### Step 4.2: Deploy Secrets (Manual Step)
**Tool**: Standard kubectl

```text
IMPORTANT: User must provide actual credentials

Command Template:
kubectl create secret generic todo-secrets \
  --namespace todo-app \
  --from-literal=DATABASE_URL="<user-provided>" \
  --from-literal=JWT_SECRET_KEY="<user-provided>" \
  --from-literal=OPENAI_API_KEY="<user-provided>"
```

#### Step 4.3: Deploy Helm Chart
**Tool**: Helm CLI

```text
Command: helm upgrade --install todo-app ./k8s/todo-app \
  --namespace todo-app \
  --set frontend.image.tag=local \
  --set backend.image.tag=local \
  --wait --timeout 5m

Flags:
- upgrade --install: Install or upgrade if exists
- --namespace: Target namespace
- --set: Override values
- --wait: Wait for pods to be ready
- --timeout: Maximum wait time
```

#### Step 4.4: Scale Frontend Replicas
**Tool**: kubectl-ai

```text
Command: kubectl-ai "scale frontend deployment to 2 replicas in todo-app namespace"

Verification: kubectl get pods -n todo-app -l app=todo-frontend
Expected: 2 frontend pods running
```

---

### Phase 5: Cluster Analysis with kagent

#### Step 5.1: Analyze Deployment Health
**Tool**: kagent

```text
Command: kagent analyze deployment todo-app -n todo-app

Expected Output:
- Pod status and health
- Resource utilization
- Events and warnings
- Recommendations for optimization
```

#### Step 5.2: Check Resource Usage
**Tool**: kagent

```text
Command: kagent resources -n todo-app

Analysis:
- CPU requests vs actual usage
- Memory requests vs actual usage
- Recommendations for right-sizing
```

#### Step 5.3: Identify Issues
**Tool**: kagent

```text
Command: kagent diagnose -n todo-app

Checks:
- Pod restart loops
- Image pull errors
- Resource constraints
- Network connectivity
```

---

### Phase 6: Validation & Verification

#### Step 6.1: Verify Pod Status
**Tool**: Standard kubectl

```text
Commands:
1. kubectl get pods -n todo-app
2. kubectl get pods -n todo-app -o wide
3. kubectl describe pods -n todo-app

Expected:
- All pods in Running state
- All containers Ready (1/1 or 2/2)
- No restarts or errors
```

#### Step 6.2: Verify Services
**Tool**: Standard kubectl

```text
Commands:
1. kubectl get services -n todo-app
2. kubectl describe service todo-frontend -n todo-app
3. kubectl describe service todo-backend -n todo-app

Expected:
- todo-frontend: NodePort on 30080
- todo-backend: ClusterIP on 8000
```

#### Step 6.3: Test Backend Health
**Tool**: kubectl exec

```text
Command: kubectl exec -n todo-app deployment/todo-backend -- curl -s localhost:8000/health

Expected: {"status": "healthy"} or similar JSON response
```

#### Step 6.4: Test Frontend Access
**Tool**: Minikube service

```text
Command: minikube service todo-frontend -n todo-app --url

Expected: URL like http://192.168.49.2:30080
Action: Open URL in browser, verify Todo Chatbot UI loads
```

#### Step 6.5: Test End-to-End Flow
**Tool**: Manual browser testing

```text
Steps:
1. Open frontend URL in browser
2. Log in or create account
3. Create a new todo item
4. Use chatbot to interact with todos
5. Verify all features work correctly
```

---

### Phase 7: Rollback & Cleanup

#### Step 7.1: Rollback Deployment (if needed)
**Tool**: Helm CLI

```text
Commands:
1. List releases: helm list -n todo-app
2. View history: helm history todo-app -n todo-app
3. Rollback: helm rollback todo-app [REVISION] -n todo-app

Use When:
- Deployment fails
- Application errors after update
- Need to restore previous version
```

#### Step 7.2: Clean Teardown
**Tool**: Helm CLI + kubectl

```text
Commands:
1. Uninstall Helm release: helm uninstall todo-app -n todo-app
2. Delete secrets: kubectl delete secret todo-secrets -n todo-app
3. Delete namespace: kubectl delete namespace todo-app

Verification: kubectl get all -n todo-app (should return "No resources found")
```

#### Step 7.3: Stop Minikube (Optional)
**Tool**: Minikube CLI

```text
Commands:
1. Stop cluster: minikube stop
2. Delete cluster: minikube delete (if complete reset needed)

Note: Stopping preserves state, deleting removes everything
```

---

## Helper Scripts Summary

### scripts/local-deploy.sh
```text
Purpose: One-command deployment
Steps:
1. Start Minikube (if not running)
2. Set Docker env
3. Build images
4. Create namespace
5. Prompt for secrets
6. Deploy Helm chart
7. Wait for pods
8. Print access URL
```

### scripts/local-teardown.sh
```text
Purpose: Clean removal
Steps:
1. Helm uninstall
2. Delete secrets
3. Delete namespace
4. (Optional) Stop Minikube
```

---

## Complexity Tracking

| Decision | Justification | Alternative Rejected |
|----------|---------------|---------------------|
| NodePort over Ingress | Simpler for local dev, no ingress controller needed | Ingress adds complexity without benefit for local |
| External DB (Neon) | Already provisioned, avoids local DB setup | Local PostgreSQL adds operational burden |
| Single Helm chart | All components in one release for simplicity | Multiple charts overcomplicates local deployment |

---

## Next Steps

1. Run `/sp.tasks` to generate detailed implementation tasks
2. Execute tasks in order following this plan
3. Create quickstart.md documentation after successful deployment
